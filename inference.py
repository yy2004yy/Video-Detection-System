"""
å•ä¸ªè§†é¢‘æ£€æµ‹è„šæœ¬ - ç»™å¯¼å¸ˆæ¼”ç¤ºç”¨
"""
import os
import argparse
import torch
from pathlib import Path
from PIL import Image
import yaml

from data.preprocess import extract_frames_from_video
from models import DeepFakeDetector
from utils import setup_logger, load_config, setup_device, load_checkpoint
from torchvision import transforms


def inference_single_video(model, video_path, device, num_frames=8, logger=None):
    """
    å¯¹å•ä¸ªè§†é¢‘è¿›è¡Œæ¨ç†
    
    Args:
        model: è®­ç»ƒå¥½çš„æ¨¡å‹
        video_path: è§†é¢‘æ–‡ä»¶è·¯å¾„
        device: è®¡ç®—è®¾å¤‡
        num_frames: æå–çš„å¸§æ•°
        logger: æ—¥å¿—è®°å½•å™¨
    
    Returns:
        dict: åŒ…å«é¢„æµ‹ç»“æœå’Œç½®ä¿¡åº¦çš„å­—å…¸
    """
    if logger:
        logger.info(f"ğŸ“¹ æ­£åœ¨å¤„ç†è§†é¢‘: {video_path}")
    
    # æå–è§†é¢‘å¸§
    frames = extract_frames_from_video(video_path, num_frames=num_frames)
    
    if logger:
        logger.info(f"âœ… æå–äº† {len(frames)} å¸§")
    
    # å›¾åƒé¢„å¤„ç†
    transform = transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
    ])
    
    # é¢„å¤„ç†æ‰€æœ‰å¸§
    processed_frames = [transform(frame) for frame in frames]
    
    # å †å ä¸ºtensor: [num_frames, C, H, W]
    frames_tensor = torch.stack(processed_frames)
    
    # æ·»åŠ batchç»´åº¦: [1, num_frames, C, H, W]
    frames_tensor = frames_tensor.unsqueeze(0).to(device)
    
    # æ¨ç†
    model.eval()
    with torch.no_grad():
        logits = model(frames_tensor)
        probs = torch.softmax(logits, dim=1)
        pred_class = logits.argmax(dim=1).item()
        confidence = probs[0][pred_class].item()
    
    # ç»“æœ
    class_names = ["çœŸå®", "è™šå‡"]
    result = {
        'video_path': video_path,
        'prediction': class_names[pred_class],
        'pred_class': pred_class,
        'confidence': confidence,
        'probabilities': {
            'çœŸå®': probs[0][0].item(),
            'è™šå‡': probs[0][1].item()
        }
    }
    
    return result


def main():
    parser = argparse.ArgumentParser(description='å•ä¸ªè§†é¢‘æ£€æµ‹æ¨ç†')
    parser.add_argument('--config', type=str, default='configs/clip_baseline.yaml',
                       help='é…ç½®æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--checkpoint', type=str, required=True,
                       help='æ¨¡å‹æ£€æŸ¥ç‚¹è·¯å¾„')
    parser.add_argument('--video', type=str, required=True,
                       help='è¦æ£€æµ‹çš„è§†é¢‘è·¯å¾„')
    parser.add_argument('--num_frames', type=int, default=8,
                       help='æå–çš„å¸§æ•°')
    args = parser.parse_args()
    
    # æ£€æŸ¥è§†é¢‘æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(args.video):
        print(f"âŒ é”™è¯¯: è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {args.video}")
        return
    
    # åŠ è½½é…ç½®
    config = load_config(args.config)
    logger = setup_logger(log_dir=config['training']['log_dir'])
    logger.info(f"ä½¿ç”¨é…ç½®æ–‡ä»¶: {args.config}")
    logger.info(f"åŠ è½½æ£€æŸ¥ç‚¹: {args.checkpoint}")
    logger.info(f"æ£€æµ‹è§†é¢‘: {args.video}")
    
    # è®¾ç½®è®¾å¤‡
    device = setup_device(config['device']['gpu_id'])
    
    # è®¾ç½®HuggingFaceé•œåƒï¼ˆå¦‚æœéœ€è¦ï¼‰
    if config.get('hf_mirror', {}).get('enabled', False):
        os.environ["HF_ENDPOINT"] = config['hf_mirror']['endpoint']
        logger.info(f"ä½¿ç”¨HuggingFaceé•œåƒ: {config['hf_mirror']['endpoint']}")
    
    # åˆ›å»ºæ¨¡å‹
    model = DeepFakeDetector(
        backbone=config['model']['backbone'],
        backbone_model_name=config['model'].get('clip_model_name') or config['model'].get('imagebind_model_name'),
        num_classes=2,
        device=device
    )
    
    # åŠ è½½æƒé‡
    checkpoint = load_checkpoint(args.checkpoint, model, device=device)
    logger.info("âœ… æ¨¡å‹æƒé‡åŠ è½½å®Œæˆ")
    
    # æ¨ç†
    logger.info("=" * 50)
    logger.info("å¼€å§‹æ¨ç†")
    logger.info("=" * 50)
    
    result = inference_single_video(
        model, args.video, device, 
        num_frames=args.num_frames, 
        logger=logger
    )
    
    # æ‰“å°ç»“æœ
    print("\n" + "=" * 50)
    print("æ£€æµ‹ç»“æœ")
    print("=" * 50)
    print(f"è§†é¢‘è·¯å¾„: {result['video_path']}")
    print(f"é¢„æµ‹ç»“æœ: {result['prediction']}")
    print(f"ç½®ä¿¡åº¦: {result['confidence']:.2%}")
    print(f"\næ¦‚ç‡åˆ†å¸ƒ:")
    print(f"  çœŸå®: {result['probabilities']['çœŸå®']:.2%}")
    print(f"  è™šå‡: {result['probabilities']['è™šå‡']:.2%}")
    print("=" * 50)
    
    logger.info("æ¨ç†å®Œæˆ")


if __name__ == "__main__":
    main()

