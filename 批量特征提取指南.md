# 批量特征提取指南 - 场景一：离线批量处理

## 📋 目录

1. [关于Clip文件夹](#关于clip文件夹)
2. [快速开始](#快速开始)
3. [详细步骤](#详细步骤)
4. [使用示例](#使用示例)
5. [性能优化建议](#性能优化建议)
6. [常见问题](#常见问题)

---

## 关于Clip文件夹

### Clip文件夹的作用

`Clip/` 文件夹包含的是**交互式问答演示系统**，主要用于：
- 演示CLIP的视觉-语言理解能力
- 交互式视频问答（输入视频+问题，输出答案）
- **不是用于批量特征提取的**

### 是否可以删除？

**答案：可以删除！**

对于你的场景（批量特征提取），`Clip/` 文件夹**不是必需的**，因为：

1. ✅ **核心CLIP功能**已经在 `models/backbones/clip_encoder.py` 中
2. ✅ **批量处理脚本**使用 `CLIPEncoder` 类，不依赖 `Clip/` 文件夹
3. ✅ `Clip/deploy_clip.py` 是用于交互式演示，不是批量处理

**建议**：
- 如果确定不需要交互式演示功能，可以删除 `Clip/` 文件夹
- 如果想保留作为演示用途，也可以保留（不影响批量处理）

---

## 快速开始

### 步骤1: 环境准备

```bash
# 激活环境（如果使用conda）
conda activate clip_env  # 或你的环境名称

# 确保已安装依赖
pip install -r requirements.txt
```

### 步骤2: 准备视频数据

将你的视频文件放在一个目录下，例如：
```
data/
└── videos/
    ├── video1.mp4
    ├── video2.mp4
    └── ...
```

### 步骤3: 运行批量提取

```bash
python extract_features.py \
    --video_dir ./data/videos \
    --output_dir ./features \
    --batch_size 64 \
    --gpu_id 0
```

---

## 详细步骤

### 1. 配置GPU

编辑 `configs/clip_baseline.yaml` 或使用命令行参数：

```yaml
device:
  gpu_id: 0  # 修改为你的GPU ID
```

或使用命令行参数：
```bash
python extract_features.py --gpu_id 0 ...
```

### 2. 设置批次大小

根据你的GPU显存调整 `batch_size`：

| GPU型号 | 推荐batch_size | 说明 |
|---------|---------------|------|
| A6000 (48GB) | 64-128 | 大显存，可以设置较大 |
| RTX 3090 (24GB) | 32-64 | 中等显存 |
| RTX 3080 (10GB) | 16-32 | 较小显存 |

**A6000建议**：从64开始，如果显存充足可以增加到128

### 3. 运行提取

```bash
python extract_features.py \
    --video_dir /path/to/your/videos \
    --output_dir ./features \
    --batch_size 64 \
    --num_frames 8 \
    --num_workers 4 \
    --save_format npy
```

### 4. 查看结果

提取完成后，特征文件保存在 `output_dir` 中：

**如果使用npy格式**：
- `features.npy` - 特征数组 [N, 512]
- `video_paths.txt` - 对应的视频路径列表

**如果使用pkl格式**：
- `features.pkl` - 包含特征和路径的字典

---

## 使用示例

### 示例1: 基本使用

```bash
# 提取DFDC数据集的特征
python extract_features.py \
    --video_dir /data/DFDC/videos \
    --output_dir ./features/dfdc \
    --batch_size 64
```

### 示例2: 使用配置文件

```bash
# 使用自定义配置文件
python extract_features.py \
    --config configs/clip_baseline.yaml \
    --video_dir ./data/videos \
    --output_dir ./features
```

### 示例3: 指定GPU和保存格式

```bash
# 使用GPU 1，保存为pkl格式
python extract_features.py \
    --video_dir ./data/videos \
    --output_dir ./features \
    --batch_size 128 \
    --gpu_id 1 \
    --save_format pkl
```

### 示例4: 加载提取的特征

```python
import numpy as np

# 加载npy格式
features = np.load('./features/features.npy')
print(f"特征形状: {features.shape}")  # [N, 512]

# 加载路径列表
with open('./features/video_paths.txt', 'r') as f:
    video_paths = [line.strip() for line in f]

# 加载pkl格式
import pickle
with open('./features/features.pkl', 'rb') as f:
    data = pickle.load(f)
    features = data['features']
    video_paths = data['video_paths']
```

---

## 性能优化建议

### 1. 批次大小优化

**A6000 (48GB显存)**：
```bash
# 保守设置
--batch_size 64

# 激进设置（如果显存充足）
--batch_size 128
```

**如何判断batch_size是否合适**：
- 如果出现 `CUDA out of memory`，减小batch_size
- 如果GPU利用率不高，可以增大batch_size

### 2. 数据加载优化

```bash
# 使用多进程加载（根据CPU核心数调整）
--num_workers 4  # 或 8

# 如果数据在SSD上，可以增加num_workers
--num_workers 8
```

### 3. 帧数优化

```bash
# 默认8帧，如果视频较长可以增加
--num_frames 8   # 平衡速度和精度
--num_frames 16  # 更高精度，但更慢
```

### 4. 24小时连续运行

```bash
# 使用nohup在后台运行
nohup python extract_features.py \
    --video_dir ./data/videos \
    --output_dir ./features \
    --batch_size 64 \
    > extract.log 2>&1 &

# 查看进度
tail -f extract.log
```

### 5. 断点续传（如果中断）

如果处理中断，可以：
1. 记录已处理的视频路径
2. 修改脚本，跳过已处理的视频
3. 或者使用更高级的分布式处理

---

## 命令行参数说明

| 参数 | 类型 | 默认值 | 说明 |
|------|------|--------|------|
| `--config` | str | `configs/clip_baseline.yaml` | 配置文件路径 |
| `--video_dir` | str | **必需** | 视频目录路径 |
| `--output_dir` | str | `./features` | 特征输出目录 |
| `--batch_size` | int | 64 | 批次大小（根据显存调整） |
| `--num_frames` | int | 8 | 每个视频提取的帧数 |
| `--num_workers` | int | 4 | 数据加载进程数 |
| `--save_format` | str | `npy` | 保存格式：`npy` 或 `pkl` |
| `--gpu_id` | int | None | GPU ID（覆盖配置文件） |

---

## 常见问题

### Q1: CUDA内存不足

**错误信息**：
```
RuntimeError: CUDA out of memory
```

**解决方案**：
1. 减小batch_size：`--batch_size 32` 或 `--batch_size 16`
2. 减少num_frames：`--num_frames 4`
3. 使用更小的CLIP模型（在配置文件中修改）

### Q2: 视频文件读取失败

**错误信息**：
```
无法打开视频文件: xxx.mp4
```

**解决方案**：
1. 检查视频文件是否损坏
2. 检查文件路径是否正确
3. 脚本会自动跳过无法读取的视频，继续处理下一个

### Q3: 处理速度慢

**可能原因和解决方案**：
1. **batch_size太小**：增大batch_size（在显存允许的情况下）
2. **num_workers太少**：增加num_workers（如 `--num_workers 8`）
3. **数据在机械硬盘**：如果可能，将数据移到SSD
4. **GPU利用率低**：检查是否有其他进程占用GPU

### Q4: 如何知道处理进度？

脚本会显示：
- 实时进度条（tqdm）
- 每100个batch打印一次日志
- 日志文件保存在 `logs/` 目录

### Q5: 特征文件太大怎么办？

**特征大小估算**：
- 每个视频：512维特征 = 512 * 4 bytes = 2KB
- 10000个视频：约20MB
- 100000个视频：约200MB

**如果文件太大**：
1. 使用pkl格式（可能更小，因为有压缩）
2. 分批保存（需要修改脚本）
3. 使用HDF5格式（需要额外修改）

### Q6: 如何验证特征提取是否正确？

```python
import numpy as np

# 加载特征
features = np.load('./features/features.npy')

# 检查形状
print(f"特征形状: {features.shape}")  # 应该是 [N, 512]

# 检查是否有NaN或Inf
print(f"NaN数量: {np.isnan(features).sum()}")
print(f"Inf数量: {np.isinf(features).sum()}")

# 检查特征范围（CLIP特征通常在[-1, 1]或normalized）
print(f"特征范围: [{features.min():.4f}, {features.max():.4f}]")
```

---

## 工作流程总结

```
1. 准备视频数据
   └── 将视频放在一个目录下

2. 运行批量提取
   └── python extract_features.py --video_dir ./data/videos --batch_size 64

3. 等待处理完成
   └── 查看进度条和日志

4. 获取特征文件
   └── features.npy 和 video_paths.txt

5. 后续使用
   └── 加载特征用于训练分类器
```

---

## 下一步

提取完特征后，你可以：

1. **训练分类器**：使用提取的特征训练一个简单的分类器（如SVM、MLP）
2. **特征分析**：分析真实和虚假视频的特征分布
3. **可视化**：使用t-SNE或PCA可视化特征空间
4. **构建Web界面**：使用提取的特征构建实时检测系统（场景三）

---


